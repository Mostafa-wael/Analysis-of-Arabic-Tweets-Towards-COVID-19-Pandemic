{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /home/mostafawael/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/mostafawael/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# For Data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from datetime import datetime\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "#  For Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.offline as pyo \n",
    "import plotly.graph_objects as go\n",
    "import plotly.figure_factory as ff\n",
    "import missingno as msno\n",
    "from wordcloud import WordCloud\n",
    "import random\n",
    "\n",
    "# For models\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "\n",
    "# For NLP\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer as SIA\n",
    "from spellchecker import SpellChecker\n",
    "\n",
    "import pickle\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "\n",
    "# For Styling\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "# Downloading periphrals\n",
    "nltk.download('vader_lexicon')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "from preprocessing import *\n",
    "from plot import *\n",
    "from feature_extractor import *\n",
    "from data_balance import *\n",
    "from model import *\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset size = (6988, 3)\n",
      "Dev dataset size = (1000, 3)\n"
     ]
    }
   ],
   "source": [
    "train_file = 'Dataset/train.csv'\n",
    "devFile = 'Dataset/dev.csv'\n",
    "train_df = pd.read_csv(train_file)\n",
    "dev_df = pd.read_csv(devFile)\n",
    "print(f\"Training dataset size = {train_df.shape}\")\n",
    "print(f\"Dev dataset size = {dev_df.shape}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned Training dataset size = (6988, 3)\n",
      "Cleaned Dev dataset size = (1000, 3)\n"
     ]
    }
   ],
   "source": [
    "# Data cleaning\n",
    "training_data = cleanData(train_df, 'training', clean = False, clearData = True)\n",
    "print(f\"Cleaned Training dataset size = {training_data.shape}\")\n",
    "# Data cleaning\n",
    "dev_data = cleanData(dev_df, 'dev', clean = False, clearData = False)\n",
    "print(f\"Cleaned Dev dataset size = {dev_data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed Training dataset size = (6988, 5)\n",
      "Index(['text', 'category', 'stance', 'Lemmatization', 'sentiment'], dtype='object')\n",
      "Processed dev dataset size = (1000, 5)\n",
      "Index(['text', 'category', 'stance', 'Lemmatization', 'sentiment'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Some preprocessing steps, like extracting limmitization\n",
    "training_data = training_data.pipe(processing)    \n",
    "print(f\"Processed Training dataset size = {training_data.shape}\")\n",
    "print(training_data.columns)\n",
    "# Some preprocessing steps, like extracting limmitization\n",
    "dev_data = processing(dev_data)   \n",
    "print(f\"Processed dev dataset size = {dev_data.shape}\")\n",
    "print(dev_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the out\n",
    "training_data.to_csv('out/training_data_processed.csv', index=False) # print the df in a csv file\n",
    "# Save the out\n",
    "dev_data.to_csv('out/dev_data_processed.csv', index=False) # print the df in a csv file"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARNING] [2022-12-25 21:40:41,732:gensim.models.word2vec] Each 'sentences' item should be a list of words (usually unicode strings). First item here is instead plain <class 'str'>.\n",
      "[WARNING] [2022-12-25 21:40:42,936:gensim.models.word2vec] Each 'sentences' item should be a list of words (usually unicode strings). First item here is instead plain <class 'str'>.\n"
     ]
    }
   ],
   "source": [
    "## Word2Vec embeddings\n",
    "model = extractWordEmbeddings(training_data['Lemmatization']) # use word2vec to extract the word embeddings\n",
    "training_data['features'] = getTweetsEmbeddings(model, training_data['Lemmatization']) # get the word embeddings for each tweet\n",
    "trainingFeatures = training_data['features'].to_numpy()\n",
    "\n",
    "## Word2Vec embeddings\n",
    "model = extractWordEmbeddings(dev_data['Lemmatization']) # use word2vec to extract the word embeddings\n",
    "dev_data['features'] = getTweetsEmbeddings(model, dev_data['Lemmatization']) # get the word embeddings for each tweet\n",
    "devFeatures = dev_data['features'].to_numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XLM embeddings\n",
    "# features = np.load('out/train_embeddings.npy')\n",
    "# XLM embeddings\n",
    "# dev_data['features'] = np.load('out/test_embeddings.npy').tolist()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Balancing the training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before balancing:\n",
      "Class=2, n=5538 (79.250%)\n",
      "Class=1, n=1012 (14.482%)\n",
      "Class=0, n=438 (6.268%)\n",
      "After balancing:\n",
      "Class=2, n=5538 (33.333%)\n",
      "Class=1, n=5538 (33.333%)\n",
      "Class=0, n=5538 (33.333%)\n",
      "Some notes about dimensions of the data\n",
      "X_train size before cleaning = (6988, 100)\n",
      "X_train size = (16614, 100)\n",
      "y_train size = (16614,)\n"
     ]
    }
   ],
   "source": [
    "# convert features into 2d array\n",
    "trainingFeatures = np.array([np.array(xi) for xi in trainingFeatures])\n",
    "stances = training_data['stance'].to_numpy()\n",
    "columns = [\"f\" + str(i + 1) for i in range(len(trainingFeatures[0]))]\n",
    "\n",
    "df = pd.DataFrame(trainingFeatures, columns=columns)\n",
    "df = pd.DataFrame(trainingFeatures)\n",
    "df['stance'] = stances\n",
    "\n",
    "X_train, y_train = balance_data(df)\n",
    "print(\"Some notes about dimensions of the data\")\n",
    "print(f\"X_train size before cleaning = {trainingFeatures.shape}\")\n",
    "print(f\"X_train size = {X_train.shape}\")\n",
    "print(f\"y_train size = {y_train.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_test size = (1398, 100)\n",
      "y_test size = (1398,)\n",
      "Unique values in the dataset = [-1  0  1]\n",
      "Unique values in the dataset = [-1  0  1]\n"
     ]
    }
   ],
   "source": [
    "split = 'y'\n",
    "if split == 'y':\n",
    "    # Split the data into train and test\n",
    "    X_train, X_test, y_train, y_test = train_test_split(trainingFeatures, stances, test_size=0.2, random_state=42)\n",
    "else:\n",
    "    X_test = np.array([np.array(xi) for xi in dev_data['features'].to_numpy()])\n",
    "    # X_test = np.load('out/test_embeddings.npy')\n",
    "    y_test = dev_data['stance'].to_numpy()\n",
    "\n",
    "print(f\"X_test size = {X_test.shape}\")\n",
    "print(f\"y_test size = {y_test.shape}\")\n",
    "# print unique values in the dataset\n",
    "print(f\"Unique values in the dataset = {np.unique(y_test)}\")\n",
    "print(f\"Unique values in the dataset = {np.unique(y_train)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Building\n",
    "**Build a multi-class classifier to predict the category of the tweet**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.50      0.04      0.08        93\n",
      "           0       0.44      0.07      0.12       208\n",
      "           1       0.80      0.98      0.88      1097\n",
      "\n",
      "    accuracy                           0.79      1398\n",
      "   macro avg       0.58      0.36      0.36      1398\n",
      "weighted avg       0.72      0.79      0.71      1398\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7854077253218884"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RandomForestClassifier\n",
    "clf = RandomForestClassifier(n_estimators=500, max_depth=15, random_state=0)\n",
    "_y_train = y_train + 1\n",
    "_y_test = y_test + 1\n",
    "model, report = modelPipeline(X_train, y_train, X_test, y_test, clf, 'out/models/clf.model')\n",
    "report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.39      0.08      0.13        93\n",
      "           1       0.41      0.12      0.19       208\n",
      "           2       0.81      0.97      0.88      1097\n",
      "\n",
      "    accuracy                           0.78      1398\n",
      "   macro avg       0.54      0.39      0.40      1398\n",
      "weighted avg       0.72      0.78      0.73      1398\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7839771101573677"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Xgboost\n",
    "xgb = XGBClassifier()\n",
    "_y_train = y_train + 1\n",
    "_y_test = y_test + 1\n",
    "model, report = modelPipeline(X_train, _y_train, X_test, _y_test, xgb, 'out/models/xgb.model')\n",
    "report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.00      0.00      0.00        93\n",
      "           0       0.00      0.00      0.00       208\n",
      "           1       0.78      1.00      0.88      1097\n",
      "\n",
      "    accuracy                           0.78      1398\n",
      "   macro avg       0.26      0.33      0.29      1398\n",
      "weighted avg       0.62      0.78      0.69      1398\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7846924177396281"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Naive Bayes\n",
    "gnb = GaussianNB(var_smoothing=10)\n",
    "model, report = modelPipeline(X_train, y_train, X_test, y_test, gnb, 'out/models/gnb.model')\n",
    "report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.00      0.00      0.00        93\n",
      "           0       0.00      0.00      0.00       208\n",
      "           1       0.78      1.00      0.88      1097\n",
      "\n",
      "    accuracy                           0.78      1398\n",
      "   macro avg       0.26      0.33      0.29      1398\n",
      "weighted avg       0.62      0.78      0.69      1398\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7846924177396281"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SVM\n",
    "svm = svm.SVC()\n",
    "model, report = modelPipeline(X_train, y_train, X_test, y_test, svm, 'out/models/svm.model')\n",
    "report"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Auto ML\n",
    "Check out the [Auto SKlearn](https://automl.github.io/auto-sklearn/master/index.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import autosklearn.classification\n",
    "import sklearn.datasets\n",
    "import sklearn.metrics\n",
    "from sklearn.utils.multiclass import type_of_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARNING] [2022-12-25 21:41:24,663:Client-AutoML(1):1d7a22e4-848c-11ed-983d-1da6501c908a] Capping the per_run_time_limit to 949.0 to have time for a least 2 models in each process.\n"
     ]
    }
   ],
   "source": [
    "automl = autosklearn.classification.AutoSklearnClassifier(\n",
    "    time_left_for_this_task=1900, # overall time in seconds\n",
    "    per_run_time_limit=1300, # time per model in seconds\n",
    "    initial_configurations_via_metalearning=0,\n",
    "    ensemble_size=10,\n",
    "    n_jobs=8,\n",
    "    smac_scenario_args={\"runcount_limit\": 1},\n",
    ")\n",
    "automl.fit(X_train, y_train)\n",
    "y_pred = automl.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auto-sklearn results:\n",
      "  Dataset name: 1d7a22e4-848c-11ed-983d-1da6501c908a\n",
      "  Metric: accuracy\n",
      "  Best validation score: 0.791328\n",
      "  Number of target algorithm runs: 1\n",
      "  Number of successful target algorithm runs: 1\n",
      "  Number of crashed target algorithm runs: 0\n",
      "  Number of target algorithms that exceeded the time limit: 0\n",
      "  Number of target algorithms that exceeded the memory limit: 0\n",
      "\n",
      "          rank  ensemble_weight           type      cost   duration\n",
      "model_id                                                           \n",
      "2            1              1.0  random_forest  0.208672  22.465421\n"
     ]
    }
   ],
   "source": [
    "print(automl.sprint_statistics())\n",
    "print(automl.leaderboard())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score 0.7825464949928469\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy score\", sklearn.metrics.accuracy_score(y_test, y_pred)) #  get the Score of the final ensemble"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
