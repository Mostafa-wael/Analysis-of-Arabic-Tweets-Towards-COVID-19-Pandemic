{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\mosel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\mosel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\mosel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\mosel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# For Data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from datetime import datetime\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "#  For Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.offline as pyo \n",
    "import plotly.graph_objects as go\n",
    "import plotly.figure_factory as ff\n",
    "import missingno as msno\n",
    "from wordcloud import WordCloud\n",
    "import random\n",
    "\n",
    "# For models\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "\n",
    "# For NLP\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer as SIA\n",
    "from spellchecker import SpellChecker\n",
    "\n",
    "import pickle\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "\n",
    "# For Styling\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "# Downloading periphrals\n",
    "nltk.download('vader_lexicon')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "from preprocessing import *\n",
    "from plot import *\n",
    "from feature_extractor import *\n",
    "from data_balance import *\n",
    "from model import *\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset size = (6988, 3)\n",
      "Dev dataset size = (1000, 3)\n"
     ]
    }
   ],
   "source": [
    "train_file = 'Dataset/train.csv'\n",
    "devFile = 'Dataset/dev.csv'\n",
    "train_df = pd.read_csv(train_file)\n",
    "dev_df = pd.read_csv(devFile)\n",
    "print(f\"Training dataset size = {train_df.shape}\")\n",
    "print(f\"Dev dataset size = {dev_df.shape}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned Training dataset size = (6988, 3)\n",
      "Cleaned Dev dataset size = (1000, 3)\n"
     ]
    }
   ],
   "source": [
    "# Data cleaning\n",
    "training_data = cleanData(train_df, 'training', clean = False, clearData = True)\n",
    "print(f\"Cleaned Training dataset size = {training_data.shape}\")\n",
    "# Data cleaning\n",
    "dev_data = cleanData(dev_df, 'dev', clean = False, clearData = True)\n",
    "print(f\"Cleaned Dev dataset size = {dev_data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed Training dataset size = (6988, 5)\n",
      "Index(['text', 'category', 'stance', 'Lemmatization', 'sentiment'], dtype='object')\n",
      "Processed dev dataset size = (1000, 5)\n",
      "Index(['text', 'category', 'stance', 'Lemmatization', 'sentiment'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Some preprocessing steps, like extracting limmitization\n",
    "training_data = training_data.pipe(processing)    \n",
    "print(f\"Processed Training dataset size = {training_data.shape}\")\n",
    "print(training_data.columns)\n",
    "# Some preprocessing steps, like extracting limmitization\n",
    "dev_data = processing(dev_data)   \n",
    "print(f\"Processed dev dataset size = {dev_data.shape}\")\n",
    "print(dev_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the out\n",
    "training_data.to_csv('out/training_data_processed.csv', index=False) # print the df in a csv file\n",
    "# Save the out\n",
    "dev_data.to_csv('out/dev_data_processed.csv', index=False) # print the df in a csv file"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Word2Vec embeddings\n",
    "model = extractWordEmbeddings(training_data['Lemmatization']) # use word2vec to extract the word embeddings\n",
    "training_data['features'] = getTweetsEmbeddings(model, training_data['Lemmatization']) # get the word embeddings for each tweet\n",
    "trainingFeatures = training_data['features'].to_numpy()\n",
    "\n",
    "## Word2Vec embeddings\n",
    "model = extractWordEmbeddings(dev_data['Lemmatization']) # use word2vec to extract the word embeddings\n",
    "dev_data['features'] = getTweetsEmbeddings(model, dev_data['Lemmatization']) # get the word embeddings for each tweet\n",
    "devFeatures = dev_data['features'].to_numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XLM embeddings\n",
    "# features = np.load('out/train_embeddings.npy')\n",
    "# XLM embeddings\n",
    "# dev_data['features'] = np.load('out/test_embeddings.npy').tolist()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Balancing the training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before balancing:\n",
      "Class=1, n=975 (13.952%)\n",
      "Class=2, n=3616 (51.746%)\n",
      "Class=4, n=1025 (14.668%)\n",
      "Class=9, n=323 (4.622%)\n",
      "Class=5, n=606 (8.672%)\n",
      "Class=6, n=112 (1.603%)\n",
      "Class=3, n=167 (2.390%)\n",
      "Class=8, n=79 (1.131%)\n",
      "Class=0, n=67 (0.959%)\n",
      "Class=7, n=18 (0.258%)\n",
      "After balancing:\n",
      "Class=1, n=3616 (10.000%)\n",
      "Class=2, n=3616 (10.000%)\n",
      "Class=4, n=3616 (10.000%)\n",
      "Class=9, n=3616 (10.000%)\n",
      "Class=5, n=3616 (10.000%)\n",
      "Class=6, n=3616 (10.000%)\n",
      "Class=3, n=3616 (10.000%)\n",
      "Class=8, n=3616 (10.000%)\n",
      "Class=0, n=3616 (10.000%)\n",
      "Class=7, n=3616 (10.000%)\n",
      "Some notes about dimensions of the data\n",
      "X_train size before cleaning = (6988, 100)\n",
      "X_train size = (36160, 100)\n",
      "y_train size = (36160,)\n"
     ]
    }
   ],
   "source": [
    "# convert features into 2d array\n",
    "trainingFeatures = np.array([np.array(xi) for xi in trainingFeatures])\n",
    "categories = training_data['category'].to_numpy()\n",
    "columns = [\"f\" + str(i + 1) for i in range(len(trainingFeatures[0]))]\n",
    "\n",
    "df = pd.DataFrame(trainingFeatures, columns=columns)\n",
    "df = pd.DataFrame(trainingFeatures)\n",
    "df['category'] = categories\n",
    "\n",
    "X_train, y_train = balance_data(df)\n",
    "print(\"Some notes about dimensions of the data\")\n",
    "print(f\"X_train size before cleaning = {trainingFeatures.shape}\")\n",
    "print(f\"X_train size = {X_train.shape}\")\n",
    "print(f\"y_train size = {y_train.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_test size = (1398, 100)\n",
      "y_test size = (1398,)\n",
      "Unique values in the dataset = ['advice' 'celebrity' 'info_news' 'others' 'personal' 'plan' 'requests'\n",
      " 'restrictions' 'rumors' 'unrelated']\n",
      "Unique values in the dataset = ['advice' 'celebrity' 'info_news' 'others' 'personal' 'plan' 'requests'\n",
      " 'restrictions' 'rumors' 'unrelated']\n"
     ]
    }
   ],
   "source": [
    "split = 'y'\n",
    "if split == 'y':\n",
    "    # Split the data into train and test\n",
    "    X_train, X_test, y_train, y_test = train_test_split(trainingFeatures, categories, test_size=0.2, random_state=42)\n",
    "else:\n",
    "    X_test = np.array([np.array(xi) for xi in dev_data['features'].to_numpy()])\n",
    "    # X_test = np.load('out/test_embeddings.npy')\n",
    "    y_test = dev_data['category'].to_numpy()\n",
    "\n",
    "print(f\"X_test size = {X_test.shape}\")\n",
    "print(f\"y_test size = {y_test.shape}\")\n",
    "# print unique values in the dataset\n",
    "print(f\"Unique values in the dataset = {np.unique(y_test)}\")\n",
    "print(f\"Unique values in the dataset = {np.unique(y_train)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Building\n",
    "**Build a multi-class classifier to predict the category of the tweet**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      advice       0.00      0.00      0.00        12\n",
      "   celebrity       0.76      0.44      0.56       194\n",
      "   info_news       0.58      0.93      0.71       718\n",
      "      others       0.00      0.00      0.00        43\n",
      "    personal       0.41      0.21      0.27       208\n",
      "        plan       0.33      0.02      0.03       113\n",
      "    requests       0.33      0.05      0.08        21\n",
      "restrictions       0.00      0.00      0.00         2\n",
      "      rumors       0.00      0.00      0.00        18\n",
      "   unrelated       0.43      0.09      0.14        69\n",
      "\n",
      "    accuracy                           0.58      1398\n",
      "   macro avg       0.28      0.17      0.18      1398\n",
      "weighted avg       0.52      0.58      0.50      1398\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.575107296137339"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RandomForestClassifier\n",
    "clf = RandomForestClassifier(n_estimators=500, max_depth=15, random_state=0)\n",
    "\n",
    "model, report = modelPipeline(X_train, y_train, X_test, y_test, clf, 'out/models/clf.model')\n",
    "report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['advice' 'celebrity' 'info_news' 'others' 'personal' 'plan' 'requests'\n",
      " 'restrictions' 'rumors' 'unrelated']\n",
      "['advice' 'celebrity' 'info_news' 'others' 'personal' 'plan' 'requests'\n",
      " 'restrictions' 'rumors' 'unrelated']\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Invalid classes inferred from unique values of `y`.  Expected: [0 1 2 3 4 5 6 7 8 9], got ['advice' 'celebrity' 'info_news' 'others' 'personal' 'plan' 'requests'\n 'restrictions' 'rumors' 'unrelated']",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[39mprint\u001b[39m(np\u001b[39m.\u001b[39munique(y_train))\n\u001b[0;32m      4\u001b[0m \u001b[39mprint\u001b[39m(np\u001b[39m.\u001b[39munique(y_test))\n\u001b[1;32m----> 5\u001b[0m model, report \u001b[39m=\u001b[39m modelPipeline(X_train, y_train, X_test, y_test, xgb, \u001b[39m'\u001b[39;49m\u001b[39mout/models/xgb.model\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m      6\u001b[0m report\n",
      "File \u001b[1;32md:\\Education\\4th year\\First Semester\\Natural Language Processing\\Project\\NLP-Project\\model.py:26\u001b[0m, in \u001b[0;36mmodelPipeline\u001b[1;34m(X_train, y_train, X_test, y_test, model, model_name)\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmodelPipeline\u001b[39m(X_train, y_train, X_test, y_test, model, model_name):\n\u001b[1;32m---> 26\u001b[0m     model \u001b[39m=\u001b[39m trainModel(X_train, y_train, model)\n\u001b[0;32m     27\u001b[0m     y_pred \u001b[39m=\u001b[39m testModel(X_test, model)\n\u001b[0;32m     28\u001b[0m     report \u001b[39m=\u001b[39m evaluateModel(y_test, y_pred)\n",
      "File \u001b[1;32md:\\Education\\4th year\\First Semester\\Natural Language Processing\\Project\\NLP-Project\\model.py:7\u001b[0m, in \u001b[0;36mtrainModel\u001b[1;34m(X_train, y_train, model)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtrainModel\u001b[39m(X_train, y_train, model):\n\u001b[1;32m----> 7\u001b[0m     model\u001b[39m.\u001b[39;49mfit(X_train, y_train)\n\u001b[0;32m      8\u001b[0m     \u001b[39mreturn\u001b[39;00m model\n",
      "File \u001b[1;32mc:\\Users\\mosel\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\xgboost\\core.py:620\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    618\u001b[0m \u001b[39mfor\u001b[39;00m k, arg \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(sig\u001b[39m.\u001b[39mparameters, args):\n\u001b[0;32m    619\u001b[0m     kwargs[k] \u001b[39m=\u001b[39m arg\n\u001b[1;32m--> 620\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\mosel\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\xgboost\\sklearn.py:1466\u001b[0m, in \u001b[0;36mXGBClassifier.fit\u001b[1;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[0;32m   1461\u001b[0m     expected_classes \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marange(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_classes_)\n\u001b[0;32m   1462\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[0;32m   1463\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclasses_\u001b[39m.\u001b[39mshape \u001b[39m!=\u001b[39m expected_classes\u001b[39m.\u001b[39mshape\n\u001b[0;32m   1464\u001b[0m     \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclasses_ \u001b[39m==\u001b[39m expected_classes)\u001b[39m.\u001b[39mall()\n\u001b[0;32m   1465\u001b[0m ):\n\u001b[1;32m-> 1466\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   1467\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mInvalid classes inferred from unique values of `y`.  \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1468\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mExpected: \u001b[39m\u001b[39m{\u001b[39;00mexpected_classes\u001b[39m}\u001b[39;00m\u001b[39m, got \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclasses_\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1469\u001b[0m     )\n\u001b[0;32m   1471\u001b[0m params \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_xgb_params()\n\u001b[0;32m   1473\u001b[0m \u001b[39mif\u001b[39;00m callable(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobjective):\n",
      "\u001b[1;31mValueError\u001b[0m: Invalid classes inferred from unique values of `y`.  Expected: [0 1 2 3 4 5 6 7 8 9], got ['advice' 'celebrity' 'info_news' 'others' 'personal' 'plan' 'requests'\n 'restrictions' 'rumors' 'unrelated']"
     ]
    }
   ],
   "source": [
    "# Xgboost\n",
    "xgb = XGBClassifier()\n",
    "model, report = modelPipeline(X_train, y_train, X_test, y_test, xgb, 'out/models/xgb.model')\n",
    "report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      advice       0.00      0.00      0.00        12\n",
      "   celebrity       0.53      0.14      0.23       194\n",
      "   info_news       0.53      0.99      0.69       718\n",
      "      others       0.00      0.00      0.00        43\n",
      "    personal       0.00      0.00      0.00       208\n",
      "        plan       0.00      0.00      0.00       113\n",
      "    requests       0.00      0.00      0.00        21\n",
      "restrictions       0.00      0.00      0.00         2\n",
      "      rumors       0.00      0.00      0.00        18\n",
      "   unrelated       0.00      0.00      0.00        69\n",
      "\n",
      "    accuracy                           0.53      1398\n",
      "   macro avg       0.11      0.11      0.09      1398\n",
      "weighted avg       0.34      0.53      0.38      1398\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5271816881258942"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Naive Bayes\n",
    "gnb = GaussianNB(var_smoothing=10)\n",
    "model, report = modelPipeline(X_train, y_train, X_test, y_test, gnb, 'out/models/gnb.model')\n",
    "report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.00      0.00      0.00        93\n",
      "           0       0.00      0.00      0.00       208\n",
      "           1       0.78      1.00      0.88      1097\n",
      "\n",
      "    accuracy                           0.78      1398\n",
      "   macro avg       0.26      0.33      0.29      1398\n",
      "weighted avg       0.62      0.78      0.69      1398\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7846924177396281"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SVM\n",
    "svm = svm.SVC()\n",
    "model, report = modelPipeline(X_train, y_train, X_test, y_test, svm, 'out/models/svm.model')\n",
    "report"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Auto ML\n",
    "Check out the [Auto SKlearn](https://automl.github.io/auto-sklearn/master/index.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import autosklearn.classification\n",
    "import sklearn.datasets\n",
    "import sklearn.metrics\n",
    "from sklearn.utils.multiclass import type_of_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARNING] [2022-12-25 22:02:19,413:Client-AutoML(1):093be1d2-848f-11ed-983d-1da6501c908a] Capping the per_run_time_limit to 949.0 to have time for a least 2 models in each process.\n"
     ]
    }
   ],
   "source": [
    "automl = autosklearn.classification.AutoSklearnClassifier(\n",
    "    time_left_for_this_task=1900, # overall time in seconds\n",
    "    per_run_time_limit=1300, # time per model in seconds\n",
    "    initial_configurations_via_metalearning=0,\n",
    "    ensemble_size=10,\n",
    "    n_jobs=8,\n",
    "    smac_scenario_args={\"runcount_limit\": 1},\n",
    ")\n",
    "automl.fit(X_train, y_train)\n",
    "y_pred = automl.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auto-sklearn results:\n",
      "  Dataset name: 093be1d2-848f-11ed-983d-1da6501c908a\n",
      "  Metric: accuracy\n",
      "  Best validation score: 0.795664\n",
      "  Number of target algorithm runs: 1\n",
      "  Number of successful target algorithm runs: 1\n",
      "  Number of crashed target algorithm runs: 0\n",
      "  Number of target algorithms that exceeded the time limit: 0\n",
      "  Number of target algorithms that exceeded the memory limit: 0\n",
      "\n",
      "          rank  ensemble_weight           type      cost   duration\n",
      "model_id                                                           \n",
      "2            1              1.0  random_forest  0.204336  20.671741\n"
     ]
    }
   ],
   "source": [
    "print(automl.sprint_statistics())\n",
    "print(automl.leaderboard())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score 0.7761087267525035\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy score\", sklearn.metrics.accuracy_score(y_test, y_pred)) #  get the Score of the final ensemble"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "43b010d9f7d982b0242266748a4ec71b1a1d9ef54f57a230cfc8a9c34419b385"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
