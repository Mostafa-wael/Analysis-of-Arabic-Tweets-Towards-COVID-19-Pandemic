{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /home/makrion/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/makrion/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /home/makrion/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/makrion/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# For Data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from datetime import datetime\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "#  For Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.offline as pyo \n",
    "import plotly.graph_objects as go\n",
    "import plotly.figure_factory as ff\n",
    "import missingno as msno\n",
    "from wordcloud import WordCloud\n",
    "import random\n",
    "\n",
    "# For models\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "\n",
    "# For NLP\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer as SIA\n",
    "from spellchecker import SpellChecker\n",
    "\n",
    "import pickle\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "\n",
    "# For Styling\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "# Downloading periphrals\n",
    "nltk.download('vader_lexicon')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "from preprocessing import *\n",
    "from plot import *\n",
    "from feature_extractor import *\n",
    "from data_balance import *\n",
    "from model import *\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODELS_PATH = 'out/models/category/'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset size = (6988, 3)\n",
      "Dev dataset size = (1000, 3)\n"
     ]
    }
   ],
   "source": [
    "train_file = 'Dataset/train.csv'\n",
    "devFile = 'Dataset/dev.csv'\n",
    "train_df = pd.read_csv(train_file)\n",
    "dev_df = pd.read_csv(devFile)\n",
    "print(f\"Training dataset size = {train_df.shape}\")\n",
    "print(f\"Dev dataset size = {dev_df.shape}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned Training dataset size = (6557, 3)\n",
      "Cleaned Dev dataset size = (1000, 3)\n"
     ]
    }
   ],
   "source": [
    "# Data cleaning\n",
    "training_data = cleanData(train_df, 'training', clean = True, clearData = True)\n",
    "print(f\"Cleaned Training dataset size = {training_data.shape}\")\n",
    "# Data cleaning\n",
    "dev_data = cleanData(dev_df, 'dev', clean = True, clearData = False)\n",
    "print(f\"Cleaned Dev dataset size = {dev_data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed Training dataset size = (6557, 5)\n",
      "Index(['text', 'category', 'stance', 'Lemmatization', 'sentiment'], dtype='object')\n",
      "Processed dev dataset size = (1000, 5)\n",
      "Index(['text', 'category', 'stance', 'Lemmatization', 'sentiment'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Some preprocessing steps, like extracting limmitization\n",
    "training_data = training_data.pipe(processing_categories)    \n",
    "print(f\"Processed Training dataset size = {training_data.shape}\")\n",
    "print(training_data.columns)\n",
    "# Some preprocessing steps, like extracting limmitization\n",
    "dev_data = processing_categories(dev_data)   \n",
    "print(f\"Processed dev dataset size = {dev_data.shape}\")\n",
    "print(dev_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the out\n",
    "training_data.to_csv('out/training_data_processed.csv', index=False) # print the df in a csv file\n",
    "# Save the out\n",
    "dev_data.to_csv('out/dev_data_processed.csv', index=False) # print the df in a csv file"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  embeddings\n",
    "w2v_model, bow_model, tfidf_model = get_feature_models(training_data['Lemmatization'].tolist()) #+dev_data['Lemmatization'].tolist()) # use word2vec to extract the word embeddings\n",
    "training_data['features'] = get_features(w2v_model, bow_model, tfidf_model, training_data['Lemmatization'], 1, 1, 1) # get the word embeddings for each tweet\n",
    "trainingFeatures = training_data['features'].to_numpy()\n",
    "\n",
    "##  embeddings\n",
    "#model = extractWordEmbeddings(dev_data['Lemmatization']) # use word2vec to extract the word embeddings\n",
    "dev_data['features'] = get_features(w2v_model, bow_model, tfidf_model, dev_data['Lemmatization'], 1, 1, 1) # get the word embeddings for each tweet\n",
    "devFeatures = dev_data['features'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "13750\n",
      "6557\n",
      "13750\n"
     ]
    }
   ],
   "source": [
    "print(len(dev_data['features']))\n",
    "print(len(dev_data['features'][0]))\n",
    "print(len(training_data['features']))\n",
    "print(len(training_data['features'][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XLM embeddings\n",
    "# features = np.load('out/train_embeddings.npy')\n",
    "# XLM embeddings\n",
    "# dev_data['features'] = np.load('out/test_embeddings.npy').tolist()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Balancing the training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert features into 2d array\n",
    "trainingFeatures = np.array([np.array(xi) for xi in trainingFeatures])\n",
    "categories = training_data['category'].to_numpy()\n",
    "columns = [\"f\" + str(i + 1) for i in range(len(trainingFeatures[0]))]\n",
    "\n",
    "df = pd.DataFrame(trainingFeatures, columns=columns)\n",
    "df = pd.DataFrame(trainingFeatures)\n",
    "df['category'] = categories\n",
    "\n",
    "X_train_balanced, y_train_balanced = balance_data(df)\n",
    "print(\"Some notes about dimensions of the data\")\n",
    "print(f\"X_train size before cleaning = {trainingFeatures.shape}\")\n",
    "print(f\"X_train size = {X_train_balanced.shape}\")\n",
    "print(f\"y_train size = {y_train_balanced.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_10090/513371420.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_train_balanced\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_balanced\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mxi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdev_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'features'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0;31m# X_test = np.load('out/test_embeddings.npy')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdev_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'stance'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_10090/513371420.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_train_balanced\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_balanced\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mxi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdev_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'features'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0;31m# X_test = np.load('out/test_embeddings.npy')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdev_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'stance'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "split = 'n'\n",
    "if split == 'y':\n",
    "    # Split the data into train and test\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_train_balanced, y_train_balanced, test_size=0.2, random_state=42)\n",
    "else:\n",
    "    X_train, y_train = X_train_balanced, y_train_balanced\n",
    "    X_test = np.array([np.array(xi) for xi in dev_data['features'].to_numpy()])\n",
    "    # X_test = np.load('out/test_embeddings.npy')\n",
    "    y_test = dev_data['stance'].to_numpy()\n",
    "\n",
    "print(f\"X_test size = {X_test.shape}\")\n",
    "print(f\"y_test size = {y_test.shape}\")\n",
    "# print unique values in the dataset\n",
    "print(f\"Unique values in the dataset = {np.unique(y_test)}\")\n",
    "print(f\"Unique values in the dataset = {np.unique(y_train)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Building\n",
    "**Build a multi-class classifier to predict the category of the tweet**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(dev_data['features']))\n",
    "print(len(dev_data['features'][0]))\n",
    "print(len(training_data['features']))\n",
    "print(len(training_data['features'][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.93      0.98      0.96       732\n",
      "           0       0.93      0.89      0.91       744\n",
      "           1       0.77      0.49      0.60       718\n",
      "           2       0.92      0.95      0.94       740\n",
      "           3       0.85      0.81      0.83       675\n",
      "           4       0.81      0.88      0.85       729\n",
      "           5       0.89      0.96      0.92       696\n",
      "           6       0.95      0.99      0.97       709\n",
      "           7       0.92      0.98      0.95       724\n",
      "           8       0.87      0.95      0.91       765\n",
      "\n",
      "    accuracy                           0.89      7232\n",
      "   macro avg       0.89      0.89      0.88      7232\n",
      "weighted avg       0.89      0.89      0.88      7232\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8897953539823009"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RandomForestClassifier\n",
    "clf = RandomForestClassifier(n_estimators=500, max_depth=15, random_state=0)\n",
    "_y_train = y_train + 1\n",
    "_y_test = y_test + 1\n",
    "model, report = modelPipeline(X_train, y_train, X_test, y_test, clf, MODELS_PATH+'clf.model')\n",
    "report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'XGBClassifier' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_80291/2274880856.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Xgboost\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mxgb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mXGBClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0m_y_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_train\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0m_y_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreport\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodelPipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_y_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_y_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxgb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'out/models/xgb.model'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'XGBClassifier' is not defined"
     ]
    }
   ],
   "source": [
    "# Xgboost\n",
    "xgb = XGBClassifier()\n",
    "_y_train = y_train + 1\n",
    "_y_test = y_test + 1\n",
    "model, report = modelPipeline(X_train, _y_train, X_test, _y_test, xgb, MODELS_PATH+ 'xgb.model')\n",
    "report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.00      0.00      0.00        93\n",
      "           0       0.00      0.00      0.00       208\n",
      "           1       0.78      1.00      0.88      1097\n",
      "\n",
      "    accuracy                           0.78      1398\n",
      "   macro avg       0.26      0.33      0.29      1398\n",
      "weighted avg       0.62      0.78      0.69      1398\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7846924177396281"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Naive Bayes\n",
    "gnb = GaussianNB(var_smoothing=10)\n",
    "model, report = modelPipeline(X_train, y_train, X_test, y_test, gnb,MODELS_PATH+ 'gnb.model')\n",
    "report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.00      0.00      0.00        93\n",
      "           0       0.00      0.00      0.00       208\n",
      "           1       0.78      1.00      0.88      1097\n",
      "\n",
      "    accuracy                           0.78      1398\n",
      "   macro avg       0.26      0.33      0.29      1398\n",
      "weighted avg       0.62      0.78      0.69      1398\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7846924177396281"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SVM\n",
    "svm = svm.SVC()\n",
    "model, report = modelPipeline(X_train, y_train, X_test, y_test, svm, MODELS_PATH+'svm.model')\n",
    "report"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Auto ML\n",
    "Check out the [Auto SKlearn](https://automl.github.io/auto-sklearn/master/index.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import autosklearn.classification\n",
    "import sklearn.datasets\n",
    "import sklearn.metrics\n",
    "from sklearn.utils.multiclass import type_of_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARNING] [2022-12-25 22:02:19,413:Client-AutoML(1):093be1d2-848f-11ed-983d-1da6501c908a] Capping the per_run_time_limit to 949.0 to have time for a least 2 models in each process.\n"
     ]
    }
   ],
   "source": [
    "automl = autosklearn.classification.AutoSklearnClassifier(\n",
    "    time_left_for_this_task=1900, # overall time in seconds\n",
    "    per_run_time_limit=1300, # time per model in seconds\n",
    "    initial_configurations_via_metalearning=0,\n",
    "    ensemble_size=10,\n",
    "    n_jobs=8,\n",
    "    smac_scenario_args={\"runcount_limit\": 1},\n",
    ")\n",
    "automl.fit(X_train, y_train)\n",
    "y_pred = automl.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auto-sklearn results:\n",
      "  Dataset name: 093be1d2-848f-11ed-983d-1da6501c908a\n",
      "  Metric: accuracy\n",
      "  Best validation score: 0.795664\n",
      "  Number of target algorithm runs: 1\n",
      "  Number of successful target algorithm runs: 1\n",
      "  Number of crashed target algorithm runs: 0\n",
      "  Number of target algorithms that exceeded the time limit: 0\n",
      "  Number of target algorithms that exceeded the memory limit: 0\n",
      "\n",
      "          rank  ensemble_weight           type      cost   duration\n",
      "model_id                                                           \n",
      "2            1              1.0  random_forest  0.204336  20.671741\n"
     ]
    }
   ],
   "source": [
    "print(automl.sprint_statistics())\n",
    "print(automl.leaderboard())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score 0.7761087267525035\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy score\", sklearn.metrics.accuracy_score(y_test, y_pred)) #  get the Score of the final ensemble"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13 (main, Aug 25 2022, 23:26:10) \n[GCC 11.2.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e0d277ff71215bc2e00e65dbe1083bb095effc9738a74808cbcc90b6ef0d8026"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
